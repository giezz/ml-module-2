{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа 8. Выбор оптимального классификатора"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой лабораторной работе вам потребуется выбрать наилучший классификатор с оптимальными параметрами для задачи про пассажиров [\"Титаника\"](https://ru.wikipedia.org/wiki/Титаник)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__  \n",
    "Загрузите данные (см. предыдущую лабораторную работу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/lab7/train.csv')\n",
    "test = pd.read_csv('../data/lab7/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__  \n",
    "Проведите предобработку данных (см. предыдущую лабораторную работу)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Age'] = train['Age'].fillna(-0.5)\n",
    "test['Age'] = test['Age'].fillna(-0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_age(df, cut_points, label_names):\n",
    "    df = df.copy()\n",
    "    df['Age'] = df['Age'].fillna(-0.5)\n",
    "    df['Age_categories'] = pd.cut(df['Age'], bins=cut_points, labels=label_names, right=True)\n",
    "    return df\n",
    "\n",
    "cut_points = [-1, 0, 5, 12, 18, 35, 60, 100]\n",
    "label_names = [\"Missing\", \"Infant\", \"Child\", \"Teenager\", \"Young_Adult\", \"Adult\", \"Senior\"]\n",
    "\n",
    "train = process_age(train,cut_points,label_names)\n",
    "test = process_age(test,cut_points,label_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummies(df: pd.DataFrame, column_name):\n",
    "    return pd.get_dummies(df, columns=[column_name])\n",
    "\n",
    "train = create_dummies(train, \"Pclass\")\n",
    "test = create_dummies(test, \"Pclass\")\n",
    "\n",
    "train = create_dummies(train, \"Sex\")\n",
    "test = create_dummies(test, \"Sex\")\n",
    "\n",
    "train = create_dummies(train, \"Age_categories\")\n",
    "test = create_dummies(test, \"Age_categories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Name', 'Age', 'Ticket', 'PassengerId', 'Cabin', 'Embarked', 'Fare', 'Parch', 'SibSp']\n",
    "train = train.drop(columns_to_drop, axis=1)\n",
    "test = test.drop(columns_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 178 entries, 761 to 102\n",
      "Data columns (total 12 columns):\n",
      " #   Column                      Non-Null Count  Dtype\n",
      "---  ------                      --------------  -----\n",
      " 0   Pclass_1                    178 non-null    bool \n",
      " 1   Pclass_2                    178 non-null    bool \n",
      " 2   Pclass_3                    178 non-null    bool \n",
      " 3   Sex_female                  178 non-null    bool \n",
      " 4   Sex_male                    178 non-null    bool \n",
      " 5   Age_categories_Missing      178 non-null    bool \n",
      " 6   Age_categories_Infant       178 non-null    bool \n",
      " 7   Age_categories_Child        178 non-null    bool \n",
      " 8   Age_categories_Teenager     178 non-null    bool \n",
      " 9   Age_categories_Young_Adult  178 non-null    bool \n",
      " 10  Age_categories_Adult        178 non-null    bool \n",
      " 11  Age_categories_Senior       178 non-null    bool \n",
      "dtypes: bool(12)\n",
      "memory usage: 3.5 KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train.drop('Survived', axis=1), train['Survived'], random_state=42, test_size=0.8)\n",
    "x_train.info()\n",
    "X = train.drop('Survived', axis=1)\n",
    "y = train['Survived']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 3.__  \n",
    "Примените масштабирование признаков (`StandardScaler`, `MinMaxScaler`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "standard_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__  \n",
    "Примените различные преобразования признаков (`PolynomialFeatures`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "features = PolynomialFeatures()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 5.__  \n",
    "Обучите несколько классификаторов, в том числе:  \n",
    "1. Логистическую регрессию (`LogisticRegression`).\n",
    "1. Метод опорных векторов (`SVC`).\n",
    "1. Метод *k* ближайших соседей (`KNeighborsClassifier`).\n",
    "1. Наивный байесовский классификатор (`MultinomialNB`).\n",
    "1. Деревья решений (`DecisionTreeClassifier`).\n",
    "1. Случайный лес (`RandomForestClassifier`).\n",
    "1. AdaBoost (`AdaBoost`).\n",
    "1. Градиентный бустинг (`GradientBoostingClassifier`).\n",
    "\n",
    "Для обучения и проверки качества можно использовать функцию `train_test_split()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 6.__  \n",
    "При помощи `Pipeline` и `GridSearchCV` выберите оптимальную архитектуру:\n",
    "1. Метод масштабирования.\n",
    "1. Степень полинома в `PolynomialFeatures`.\n",
    "1. Параметры классификаторов (в том числе, параметры регуляризации).\n",
    "\n",
    "Заносите в таблицу Excel результаты тестирования (варианты параметров, оценки качества)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "def train_with_cv(X, y, clf, scaler, param_dist=None):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        (\"scaler\", scaler), \n",
    "        (\"poly\", PolynomialFeatures()), \n",
    "        (\"model\", clf),])\n",
    "    cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    grid = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_dist,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=cv,\n",
    "        n_jobs=4)\n",
    "    grid.fit(X, y)\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training LogisticRegression...\n",
      "\n",
      "==================================================\n",
      "Training SVC...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[172], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclassifier\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 66\u001b[0m results[name] \u001b[38;5;241m=\u001b[39m train_with_cv(\n\u001b[0;32m     67\u001b[0m     X, y,\n\u001b[0;32m     68\u001b[0m     classifier,\n\u001b[0;32m     69\u001b[0m     StandardScaler(),\n\u001b[0;32m     70\u001b[0m     classifier_params[name])\n",
      "Cell \u001b[1;32mIn[151], line 18\u001b[0m, in \u001b[0;36mtrain_with_cv\u001b[1;34m(X, y, clf, scaler, param_dist)\u001b[0m\n\u001b[0;32m     11\u001b[0m cv \u001b[38;5;241m=\u001b[39m KFold(n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     12\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     13\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mpipeline,\n\u001b[0;32m     14\u001b[0m     param_grid\u001b[38;5;241m=\u001b[39mparam_dist,\n\u001b[0;32m     15\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     16\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[0;32m     17\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 18\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X, y)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grid\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1018\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1013\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1018\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1572\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1570\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1572\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:964\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    957\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[0;32m    958\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    959\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m    960\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[0;32m    961\u001b[0m         )\n\u001b[0;32m    962\u001b[0m     )\n\u001b[1;32m--> 964\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[0;32m    965\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    966\u001b[0m         clone(base_estimator),\n\u001b[0;32m    967\u001b[0m         X,\n\u001b[0;32m    968\u001b[0m         y,\n\u001b[0;32m    969\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[0;32m    970\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[0;32m    971\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[0;32m    972\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[0;32m    973\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[0;32m    974\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[0;32m    975\u001b[0m     )\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[0;32m    977\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params),\n\u001b[0;32m    978\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39msplitter\u001b[38;5;241m.\u001b[39msplit)),\n\u001b[0;32m    979\u001b[0m     )\n\u001b[0;32m    980\u001b[0m )\n\u001b[0;32m    982\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    983\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    984\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    985\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    986\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    987\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     69\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     70\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     73\u001b[0m )\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\anaconda3\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"lg\": LogisticRegression(),\n",
    "    \"svm\": svm.SVC(),\n",
    "    \"knn\": KNeighborsClassifier(),\n",
    "    \"mnb\": MultinomialNB(),\n",
    "    \"dtc\": DecisionTreeClassifier(),\n",
    "    \"rfc\": RandomForestClassifier(),\n",
    "    \"ada\": AdaBoostClassifier(),\n",
    "    \"gbc\": GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "classifier_params = {\n",
    "    \"lg\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        # 'model__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "        'model__C': [0.01, 0.1, 1, 10],\n",
    "        'model__max_iter': [100, 500]\n",
    "    },\n",
    "    \"svm\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__C': [0.1, 1, 10],\n",
    "        'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "        'model__gamma': ['scale', 'auto', 0.1],\n",
    "        'model__degree': [2, 3]\n",
    "    },\n",
    "    \"knn\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__n_neighbors': [3, 5, 7, 9],\n",
    "        'model__weights': ['uniform', 'distance'],\n",
    "        'model__algorithm': ['auto', 'ball_tree'],\n",
    "    },\n",
    "    \"mnb\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__alpha': [0.1, 0.5, 1.0],\n",
    "        'model__fit_prior': [True, False]\n",
    "    },\n",
    "    \"dtc\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__max_depth': [None, 5, 10],\n",
    "        'model__criterion': ['gini', 'entropy']\n",
    "    },\n",
    "    \"rfc\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__max_depth': [None, 5, 10],\n",
    "    },\n",
    "    \"ada\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__n_estimators': [50, 100],\n",
    "        'model__learning_rate': [0.01, 0.1, 1.0],\n",
    "        'model__algorithm': ['SAMME', 'SAMME.R']\n",
    "    },\n",
    "    \"gbc\": {\n",
    "        'poly__degree': [1, 2, 3, 4],\n",
    "        'model__n_estimators': [100, 200],\n",
    "        'model__learning_rate': [0.05, 0.1, 0.2],\n",
    "        'model__max_depth': [3, 5],\n",
    "    }\n",
    "}\n",
    "\n",
    "results = {}\n",
    "# scaler = \n",
    "for name, classifier in classifiers.items():\n",
    "    print(f\"\\n{'=' * 50}\")\n",
    "    print(f\"Training {classifier.__class__.__name__}...\")\n",
    "    results[name] = train_with_cv(\n",
    "        X, y,\n",
    "        classifier,\n",
    "        StandardScaler(),\n",
    "        classifier_params[name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lg': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', LogisticRegression())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__C': [0.01, 0.1, 1, 10],\n",
       "                          'model__max_iter': [100, 500],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'svm': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', SVC())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__C': [0.1, 1, 10], 'model__degree': [2, 3],\n",
       "                          'model__gamma': ['scale', 'auto', 0.1],\n",
       "                          'model__kernel': ['linear', 'rbf', 'poly'],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'knn': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', KNeighborsClassifier())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__algorithm': ['auto', 'ball_tree'],\n",
       "                          'model__n_neighbors': [3, 5, 7, 9],\n",
       "                          'model__weights': ['uniform', 'distance'],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'mnb': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', MultinomialNB())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__alpha': [0.1, 0.5, 1.0],\n",
       "                          'model__fit_prior': [True, False],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'dtc': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', DecisionTreeClassifier())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__criterion': ['gini', 'entropy'],\n",
       "                          'model__max_depth': [None, 5, 10],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'rfc': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', RandomForestClassifier())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__max_depth': [None, 5, 10],\n",
       "                          'model__n_estimators': [100, 200],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'ada': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model', AdaBoostClassifier())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__algorithm': ['SAMME', 'SAMME.R'],\n",
       "                          'model__learning_rate': [0.01, 0.1, 1.0],\n",
       "                          'model__n_estimators': [50, 100],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy'),\n",
       " 'gbc': GridSearchCV(cv=KFold(n_splits=10, random_state=42, shuffle=True),\n",
       "              estimator=Pipeline(steps=[('scaler', MinMaxScaler()),\n",
       "                                        ('poly', PolynomialFeatures()),\n",
       "                                        ('model',\n",
       "                                         GradientBoostingClassifier())]),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'model__learning_rate': [0.05, 0.1, 0.2],\n",
       "                          'model__max_depth': [3, 5],\n",
       "                          'model__n_estimators': [100, 200],\n",
       "                          'poly__degree': [1, 2, 3, 4]},\n",
       "              scoring='accuracy')}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>estimator</th>\n",
       "      <th>best_params</th>\n",
       "      <th>best_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gbc</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(degree=1),...</td>\n",
       "      <td>{'model__learning_rate': 0.05, 'model__max_dep...</td>\n",
       "      <td>0.820400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ada</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(), (Decisi...</td>\n",
       "      <td>{'model__algorithm': 'SAMME', 'model__learning...</td>\n",
       "      <td>0.819276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>knn</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(), KNeighb...</td>\n",
       "      <td>{'model__algorithm': 'auto', 'model__n_neighbo...</td>\n",
       "      <td>0.817066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rfc</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(degree=1),...</td>\n",
       "      <td>{'model__max_depth': 5, 'model__n_estimators':...</td>\n",
       "      <td>0.815918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lg</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(), Logisti...</td>\n",
       "      <td>{'model__C': 0.1, 'model__max_iter': 100, 'pol...</td>\n",
       "      <td>0.814819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dtc</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(degree=1),...</td>\n",
       "      <td>{'model__criterion': 'gini', 'model__max_depth...</td>\n",
       "      <td>0.813670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>svm</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(degree=4),...</td>\n",
       "      <td>{'model__C': 0.1, 'model__degree': 2, 'model__...</td>\n",
       "      <td>0.812547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mnb</td>\n",
       "      <td>(MinMaxScaler(), PolynomialFeatures(degree=4),...</td>\n",
       "      <td>{'model__alpha': 1.0, 'model__fit_prior': True...</td>\n",
       "      <td>0.802422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model                                          estimator  \\\n",
       "7   gbc  (MinMaxScaler(), PolynomialFeatures(degree=1),...   \n",
       "6   ada  (MinMaxScaler(), PolynomialFeatures(), (Decisi...   \n",
       "2   knn  (MinMaxScaler(), PolynomialFeatures(), KNeighb...   \n",
       "5   rfc  (MinMaxScaler(), PolynomialFeatures(degree=1),...   \n",
       "0    lg  (MinMaxScaler(), PolynomialFeatures(), Logisti...   \n",
       "4   dtc  (MinMaxScaler(), PolynomialFeatures(degree=1),...   \n",
       "1   svm  (MinMaxScaler(), PolynomialFeatures(degree=4),...   \n",
       "3   mnb  (MinMaxScaler(), PolynomialFeatures(degree=4),...   \n",
       "\n",
       "                                         best_params  best_score  \n",
       "7  {'model__learning_rate': 0.05, 'model__max_dep...    0.820400  \n",
       "6  {'model__algorithm': 'SAMME', 'model__learning...    0.819276  \n",
       "2  {'model__algorithm': 'auto', 'model__n_neighbo...    0.817066  \n",
       "5  {'model__max_depth': 5, 'model__n_estimators':...    0.815918  \n",
       "0  {'model__C': 0.1, 'model__max_iter': 100, 'pol...    0.814819  \n",
       "4  {'model__criterion': 'gini', 'model__max_depth...    0.813670  \n",
       "1  {'model__C': 0.1, 'model__degree': 2, 'model__...    0.812547  \n",
       "3  {'model__alpha': 1.0, 'model__fit_prior': True...    0.802422  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_dict = []\n",
    "for key, grid in results.items():\n",
    "    result_dict.append({\n",
    "        \"model\": key,\n",
    "        \"estimator\": grid.best_estimator_,\n",
    "        \"best_params\": grid.best_params_,\n",
    "        \"best_score\": grid.best_score_\n",
    "    })\n",
    "\n",
    "result_dict_df = pd.DataFrame(result_dict)\n",
    "result_dict_df.sort_values(by=[\"best_score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 7.__  \n",
    "1. Выберите несколько лучших классификаторов (от 3 до 10).\n",
    "1. Обучите выбранные классификаторы на всех доступных размеченных данных.\n",
    "1. Получите результаты предсказания для тестовых данных.\n",
    "1. Отправьте результаты на сервер [Kaggle](https://ru.wikipedia.org/wiki/Титаник)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier\n",
      "AdaBoostClassifier\n",
      "KNeighborsClassifier\n",
      "RandomForestClassifier\n",
      "LogisticRegression\n"
     ]
    }
   ],
   "source": [
    "clfs = result_dict_df.sort_values(by=[\"best_score\"], ascending=False)['estimator']\n",
    "trained_clfs = []\n",
    "for clf in clfs[:5]:\n",
    "    trained_clfs.append(clf.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in trained_clfs:\n",
    "    predictions = clf.predict(test)\n",
    "    test_ids = pd.read_csv('../data/lab7/test.csv')[\"PassengerId\"]\n",
    "    submission_df = {\"PassengerId\": test_ids, \"Survived\": predictions}\n",
    "    submission = pd.DataFrame(submission_df)\n",
    "    submission.to_csv(f'{type(clf[\"model\"]).__name__}__titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
